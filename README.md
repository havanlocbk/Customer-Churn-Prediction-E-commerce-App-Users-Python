
# ğŸ“‰ Customer Churn Prediction â€“ E-commerce App Users â€“ Python & scikit-learn

**Author:** Loc Ha  
**Date:** 2025 August  

---

## ğŸ›  Tools Used
![Python](https://img.shields.io/badge/Code-Python-blue)
![Pandas](https://img.shields.io/badge/Library-Pandas-yellow)
![scikit-learn](https://img.shields.io/badge/Library-scikit--learn-orange)
![Matplotlib](https://img.shields.io/badge/Library-Matplotlib-green)
![Seaborn](https://img.shields.io/badge/Library-Seaborn-red)

---

## ğŸ“‘ Table of Contents
I. [ğŸ“Œ Business Context & Objective](#-business-context--objective)  
II. [ğŸ“‚ Dataset Description & Structure](#-dataset-description--structure)  
III. [âš’ï¸ Main Process](#%EF%B8%8F-main-process)  
IV. [ğŸ“Š Key Insights & Recommendations](#-key-insights--recommendations)  

---

## ğŸ“Œ Business Context & Objective

### ğŸ¢ Business Question
How can we **predict and understand churn behavior** among e-commerce app users to design effective retention strategies?  

### ğŸ¯ Objective
- Identify behavioral patterns of churned users.  
- Build a **Machine Learning model** to predict churn with high recall/precision balance.  
- Segment churned users into groups for **personalized marketing campaigns**.  

---

## ğŸ“‚ Dataset Description & Structure

- **Source**: E-commerce churn dataset (simulated).  
- **Size**: 5,630 rows Ã— 20 columns  
- **Target column**: `Churn` (0 = Active, 1 = Churned)  
- **Missing values**: present in Tenure, DaySinceLastOrder, WarehouseToHome, CouponUsed, etc. (~200â€“300 each).  
- **ID column**: `CustomerID`  

### ğŸ§© Data Structure (Simplified)

| Column Name               | Type    | Description                                   |
|---------------------------|---------|-----------------------------------------------|
| CustomerID                | Int     | Unique identifier                             |
| Churn                     | Int     | Target: 1=churned, 0=active                   |
| Tenure                    | Float   | Months of relationship                        |
| PreferredLoginDevice      | Object  | Device used (Mobile/App/Web)                  |
| CityTier                  | Int     | Customer city tier (1â€“3)                      |
| WarehouseToHome           | Float   | Distance (km)                                 |
| PreferredPaymentMode      | Object  | COD, DebitCard, CreditCard, etc.              |
| Gender                    | Object  | Male/Female                                   |
| HourSpendOnApp            | Float   | Time spent daily on app                       |
| NumberOfDeviceRegistered  | Int     | Registered devices                            |
| PreferedOrderCat          | Object  | Preferred shopping category                   |
| SatisfactionScore         | Int     | Satisfaction score (1â€“5)                      |
| MaritalStatus             | Object  | Single/Married                                |
| NumberOfAddress           | Int     | Number of saved addresses                     |
| Complain                  | Int     | Whether user complained (0/1)                 |
| OrderAmountHikeFromlastYear | Float | Increase in order amount vs last year         |
| CouponUsed                | Float   | Number of coupons used                        |
| OrderCount                | Float   | Total orders                                  |
| DaySinceLastOrder         | Float   | Days since last order                         |
| CashbackAmount            | Int     | Cashback received                             |

---

## âš’ï¸ Main Process

1. **Exploratory Data Analysis (EDA)**  
   - Load dataset from Google Sheets (CSV format).  
   - Inspect columns, datatypes, and summary statistics.  
   - Check class distribution of target `Churn`.  
   - Identify missing values.  

   <details>
   <summary>ğŸ“Œ View Python code for EDA </summary>

   ```python
   # Load libraries
   import pandas as pd
   import seaborn as sns
   import matplotlib.pyplot as plt
   from scipy.stats import chi2_contingency, ttest_ind

   # Load dataset from Google Sheets
   file_id = "1yxgr0Qj3TiXRehYa0PED1t4zIga9gdY5"
   url = f"https://docs.google.com/spreadsheets/d/{file_id}/export?format=csv"
   df = pd.read_csv(url)

   # Inspect data
   print(df.head())
   print(df.columns)
   df.info()
   df.describe()

   # Target distribution
   print(df['Churn'].value_counts(normalize=True))

   # Missing values
   print(df.isnull().sum())

2. **Exploratory Data Analysis â€“ Numeric Features Correlation**  
   - Select numeric variables: `Tenure`, `SatisfactionScore`, `DaySinceLastOrder`, `OrderCount`, `CouponUsed`, `CashbackAmount`, `HourSpendOnApp`.  
   - Calculate Pearson correlation between numeric features and `Churn`.  
   - Visualize correlations with bar chart.  

   <details>
   <summary>ğŸ“Œ View Python code for Numeric Correlation </summary>

   ```python
   # Correlation analysis
   numeric_cols = ['Tenure','SatisfactionScore','DaySinceLastOrder',
                   'OrderCount','CouponUsed','CashbackAmount','HourSpendOnApp']

   corrs = {}
   for col in numeric_cols:
       corrs[col] = df[col].corr(df['Churn'])  # Pearson correlation (0/1 with numeric)

   print("Correlation with Churn:")
   for k,v in corrs.items():
       print(f"{k}: {v:.3f}")

   # Visualization
   corr_df = pd.DataFrame.from_dict(corrs, orient='index', columns=['Correlation']).sort_values(by='Correlation')

   plt.figure(figsize=(8,5))
   sns.barplot(x=corr_df.index, y='Correlation', data=corr_df, palette="coolwarm")
   plt.xticks(rotation=45)
   plt.title("Point Biserial Correlation between Churn and Numeric Features")
   plt.axhline(0, color='black', linestyle='--')
   plt.show()
   ```
   </details>
      
   ### ğŸ“Output (correlation values):
   
   - Tenure: -0.349
   
   - SatisfactionScore: 0.105
   
   - DaySinceLastOrder: -0.161
   
   - OrderCount: -0.029
   
   - CouponUsed: -0.008
   
   - CashbackAmount: -0.154
   
   - HourSpendOnApp: 0.019
   
   ### ğŸ“Š Visualization
   Bar chart showing correlations  
   <img width="706" height="560" alt="image" src="https://github.com/user-attachments/assets/bf33d456-16cb-496a-b626-98df4bc13b5c" />

      **Interpretation:**  
   - Longer **Tenure** and higher **CashbackAmount** strongly reduce churn.  
   - More **recent orders** also reduce churn (DaySinceLastOrder negative).  
   - **SatisfactionScore** shows a surprising positive correlation â†’ may indicate misalignment between score and true loyalty.  
   - **OrderCount**, **CouponUsed**, **HourSpendOnApp** have near-zero impact on churn.  

### 3. Categorical Features â€“ Chi-square Test

<details>
  <summary>ğŸ“Œ View Python code</summary>

```python
# PhÃ¢n tÃ­ch vá»›i biáº¿n phÃ¢n loáº¡i (Categorical features) - Chi-square test

cat_cols = ['PreferredLoginDevice','PreferredPaymentMode','Gender',
            'MaritalStatus','PreferedOrderCat','Complain']

# 1. Chuáº©n hÃ³a text trong cÃ¡c cá»™t phÃ¢n loáº¡i - Standardize text
for col in cat_cols:
    df[col] = df[col].astype(str).str.strip().str.title()  # Ä‘á»“ng nháº¥t viáº¿t hoa chá»¯ cÃ¡i Ä‘áº§u

# 2. Mapping thá»§ cÃ´ng náº¿u cÃ³ giÃ¡ trá»‹ cáº§n gá»™p - Mapping values manually
replace_dict = {
    'PreferredLoginDevice': {
        'Mobile Phone': 'Phone',
        'Phone': 'Phone'
    },
    'PreferredPaymentMode': {
        'Debit Card': 'Card',
        'Credit Card': 'Card',
        'Cc': 'Card',
        'Cash On Delivery':'COD',
        'Cod':'COD'
    },
}

df = df.replace(replace_dict)  # Replace vÃ  chuáº©n hÃ³a giÃ¡ trá»‹

# 3. PhÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a
for col in cat_cols:

    # Kiá»ƒm Ä‘á»‹nh Chi-square
    crosstab = pd.crosstab(df[col], df['Churn'])
    chi2, p, dof, ex = chi2_contingency(crosstab)

    # TÃ­nh churn rate + sá»‘ lÆ°á»£ng
    summary = df.groupby(col)['Churn'].agg(['mean','count','sum'])
    summary = summary.rename(columns={'mean':'ChurnRate','count':'Total','sum':'Churned'})
    summary = summary.sort_values(by='ChurnRate', ascending=False)

    # In báº£ng káº¿t quáº£
    print(f"\n=== {col} ===")
    print(summary.round(3))
    print(f"Chi-square test p-value = {p:.6f}")

    # Váº½ chart
    plt.figure(figsize=(6,4))
    sns.barplot(x=summary.index, y=summary['ChurnRate'], palette="viridis")
    plt.title(f"Churn rate by {col}")
    plt.ylabel("Churn rate")
    plt.xticks(rotation=45)
    plt.show()
```
</details>

   === PreferredLoginDevice ===
                         ChurnRate  Total  Churned
   PreferredLoginDevice                           
   Computer                  0.198   1634      324
   Phone                     0.156   3996      624
   
   Chi-square test p-value = 0.000148
   <img width="553" height="438" alt="image" src="https://github.com/user-attachments/assets/c626a3bc-972a-4d6e-96c1-d187f2320416" />

---

## ğŸ“Š Key Insights & Recommendations

### ğŸ’¡ Insights from EDA
- **Tenure**: Lower tenure â†’ higher churn â†’ retention strategy for new users.  
- **DaySinceLastOrder**: More inactive days â†’ higher churn â†’ reactivation campaigns needed.  
- **CashbackAmount**: More cashback â†’ less churn â†’ cashback effective as retention lever.  
- **COD Payment**: COD users churn more â†’ promote digital payments.  
- **Complain**: Complaints strongly linked to churn â†’ need complaint resolution focus.  
- **iPhone users**: Highest churn rate â†’ investigate reasons (UX, compatibility, service).  

### ğŸ” Segmentation Results (Clusters)
- **Cluster 0**: Long-tenure, high cashback, low activity â†’ loyalty rewards & small-order coupons.  
- **Cluster 1**: High order count, high coupon use, but low satisfaction â†’ improve delivery & service quality.  
- **Cluster 2**: New users, high app usage, high satisfaction â†’ encourage repeat orders with welcome coupons.  
- **Cluster 3**: Very new, low activity â†’ onboarding campaigns, free shipping & first-purchase vouchers.  

### ğŸ“ Recommendations
1. Retain **long-tenure users** with loyalty programs.  
2. Target **COD users & complainers** with education + resolution.  
3. Encourage **digital payments** & cashback-based campaigns.  
4. Reactivate inactive users via personalized promotions.  
5. Segment-specific promotions (based on cluster analysis).  

---
